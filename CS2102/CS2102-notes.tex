\documentclass[12pt, landscape]{article}
\usepackage[scaled=0.92]{helvet}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
%\usepackage{hyperref}

\usepackage{newtxtext} 

%for strikeout
\usepackage{ulem}

%For editing parbox
\usepackage[table]{xcolor}
%For editing itemise margins, reduce item separaion and list separation
\usepackage{enumitem}
\setlist[itemize]{noitemsep}
\usepackage{makecell}

% For math
\usepackage{amsmath,amsthm,amsfonts,amssymb}

% For justifying
\usepackage{ragged2e}
\justifying

%For pictures / figures
\usepackage{color,graphicx,overpic}
\graphicspath{ {./images/} }

%\usepackage{newtxtext} 
%\usepackage{amssymb}
%\usepackage[table]{xcolor}
%\usepackage{vwcol}
%\usepackage{tikz}
%\usepackage{wrapfig}
%\usepackage{makecell}


% For Code Blocks
\usepackage{xcolor}
\usepackage{listings}



%Helpful:
%[linewidth = 1.0 \linewidth]
%\lstinline{}
% use \code{} for \lstinline with colorbox.
\newcommand{\code}[1]{\colorbox{gray!25!}{\lstinline|#1|}}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{mygray}{rgb}{0.9,0.9,0.9}

\lstset{frame=tb,
  language=SQL,
  aboveskip=1mm,
  belowskip=1mm,
  showstringspaces=false, 
  columns=flexible,
  backgroundcolor=\color{mygray},
  basicstyle={\footnotesize\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\footnotesize\color{blue},
  commentstyle=\footnotesize\color{dkgreen},
  stringstyle=\footnotesize\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=2
}

% Template: Cheatsheet with code enabled

%--------------------------- PACKAGES ABOVE --------------------------------------------------------------

\pdfinfo{
  /Title (CS2102 Mids Summary.pdf)
  /Creator (Ger Teck)
  /Author (Ger Teck)
  /Subject ()
  /Keywords (tex)}

%% Margins for PAPER

% This sets page margins to .5 inch if using letter paper, and to 1cm
% if using A4 paper. (This probably isn't strictly necessary.)
% If using another size paper, use default 1cm margins.
\ifthenelse{\lengthtest { \paperwidth = 11in}}
	{ \geometry{top=.3in,left=.3in,right=.3in,bottom=.3in} }
	{\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
	}

% Turn off header and footer
\pagestyle{empty}

% for tight centres (less spacing)
\newenvironment{tightcenter}{%
  \setlength\topsep{0.5pt}
  \setlength\parskip{0.5pt}
  \begin{center}
}{%
  \end{center}
}

% Redefine section commands to use less space
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\normalfont\large\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0.1mm}%
                                {-1explus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0.1mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\small\bfseries}}
% change font
%\renewcommand{\familydefault}{\sfdefault}
%\renewcommand\rmdefault{\sfdefault}
\linespread{1.05}

\makeatother

% Define BibTeX command
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Don't print section numbers
\setcounter{secnumdepth}{0}

\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}

%% this changes all items (enumerate and itemize, reduce margins)
\setlength{\leftmargini}{0.5cm}
\setlength{\leftmarginii}{0.5cm}
\setlist[itemize,1]{leftmargin=2mm,labelindent=1mm,labelsep=1mm, itemsep = 1mm}
\setlist[itemize,2]{leftmargin=4mm,labelindent=1mm,labelsep=1mm, itemsep = 1mm}
\itemsep = 0mm
\setlist{nosep}

% Need Logo Picture
%Watermark Top Right
%\usepackage{atbegshi,picture}
%\AtBeginShipout{\AtBeginShipoutUpperLeft{%
 % \put(\dimexpr\paperwidth-1.2cm\relax, -1.2cm){\makebox[0pt][r]{\framebox{\includegraphics[width = 0.3cm]{mountainbooks} Ger Teck}}}%
%}}


% -------------------------------------------------------------------------------

% START OF DOCUMENT HERE

\begin{document}
\raggedright
\footnotesize
\begin{multicols*}{3}



% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

%% DOCUMENT NAME HERE
\begin{center}
     \Large{\textbf{CS2102 Database Sys Summary}} \\
\end{center}

AY23/24 Sem 1, github.com/gerteck
  
\section{Topics \& Objectives}
\justify{
\begin{itemize}
	\item \textbf{Design}: Entity-Relationship (ER) Model, Functional Dependencies, Normal Forms
	\item \textbf{Implementation}: SQL (Data definition language, Queries, Stored procedures, Triggers)
	\item\textbf{Theory}: Relational Calculus and algebra
	\item Module covers fundamental concpets and techniques for:
	\begin{itemize}
		\item Understanding and practice of design \& implementation of database applications and management of data with relational db management systems.
		\item Design of ER data models to capture data requirements, translate to relational database schema, refine using schema decompositions to avoid anomalies.
		\item Use SQL to define relational schemas, write queries.
		\item Reason about correctness using concepts of formal query lang (relational calculus \& algebra) and apply knowledge to develop database applications.	
	\end{itemize}
\end{itemize}
}
\centerline{\includegraphics[width=0.9 \linewidth]{roadmap}}

\section{1. Database Management Sys DBMS}
\subsubsection{Challenges for Data-Intensive applications}
\justify{
\begin{itemize}
	\item \textbf{Efficiency}: Fast access to information in volumes of data
	\item \textbf{Transactions}: "All or nothing" changes to data
	\item \textbf{Data Integrity}: Parallel access and changes to data
	\item \textbf{Recovery}: Fast and reliable handling of failures (e.g. HDD/Sys crash, power outage, network disruption)
	\item \textbf{Security}:  Fine-grained data access rights
\end{itemize}
  
\subsubsection{File-based data management to DBMS}
\begin{itemize}
	\item Complex, low level code, Often similar requirements across different programs
	\item \textbf{Problems}:  High development effort, Long development times, Higher risk of (critical) errors
	\item \textbf{DBMS}:  Set off universal and powerful functionalities for data management, with faster application development, higher stability, less errors.
\end{itemize}

\subsubsection{Core concepts of DBMS}
\begin{itemize}
	\item \textbf{ACID Transaction}:  Finite sequence of database operations (reads and/or writes), smallest logical unit of work
	\item \textbf{Atomicity}:  either all effects of T are reflected in the database or none ("all or nothing")
	\item \textbf{Consistency}: the execution of T guarantees to yield a correct state of the database
	\item \textbf{Isolation}:  execution of T is isolated from the effects of concurrent transactions
	\item \textbf{Durability}: after commit of T, its effects are permanent even in case of failures 
\end{itemize}

\subsubsection{Concurrent Execution}
\centerline{\includegraphics[width= 1 \linewidth]{concurrentproblems}}
Require Serializable transaction execution:
\begin{itemize}
	\item A concurrent execution of a set of transactions is serializable if this execution 
	is equivalent to some serial execution of the same set of transactions
	\item Two executions are equivalent if they have the same effect on the data
	\item \textbf{DBMS}: Support concurrent executions of transactions to optimize performance, Enforce serializability of concurrent executions to ensure integrity of data
\end{itemize}
}

\subsubsection{Data Abstraction}
\centerline{\includegraphics[width= 1\linewidth]{dataabstraction}}
\subsubsection{Data Independence}
\centerline{\includegraphics[width= 1\linewidth]{dataindependence}}

\justify{
\subsection{Terminology / Definitions}
\begin{itemize}
	\item \textbf{Data Model}: Collection of concepts for describing data
	\item \textbf{Schema}: Description of structure of DB using data model
	\item \textbf{Schema Instance}: Content of a DB at a particular time
\end{itemize}
\subsubsection{Relational Data Model}
Data is modelled by relations, and each relation has a definition called a relation schema. This schema specifies attributes (columns) and data constrains (e.g. domain constraints)
\begin{itemize}
	\item \textbf{Relation}: Can be seen as Tables with rows and columns:
	\begin{itemize}
		\item No. of cols = Degree/Arity, No. of rows = Cardinality
		\item Each row is called a tuple/record. It has a component for each attribute of the relation.
		\item A relation is thus a set of tuples and an instance of the relation schema, i.e. of a single table.
	\end{itemize}
	\item \textbf{Domain}: Set of atomic values, e.g. integers. All values for an attribute is either in this domain or null.
	\item \textbf{Relational database schema}: Set of relation schemas and their data constraints, i.e. of multiple tables
	\item \textbf{Relational database}:  Instance of the schema and is a collection of tables.
\end{itemize}
\centerline{\includegraphics[width=1 \linewidth]{relationalterms}}

\subsection{Integrity Constraints}
Condition that restricts the data that can be stored in a database instance. A legal relation instance is a relation that satisfies all specified ICs.
\begin{itemize}
	\item \textbf{Domain Constraints}:  Restrict the attribute values of relations, e.g. only integers allowed
	\item \textbf{Key Constraints}:
	\begin{itemize}
		\item \textbf{Superkey}: A superkey is a subset of attributes in a relation that unique identifies its tuples.
		\item \textbf{Key}:  A key is a superkey which is minimal, i.e. no proper subset of itself is a superkey. 
		\item \textbf{Candidate keys}: Set of all possible keys for a relation. One of these keys is selected as the primary key.
		\item \textbf{Primary key}: Chosen candidate key for a relation, Cannot be null (entity integrity constraint), Underlined in relation schema. Prime attribute: Attribute of a primary key (cannot be null)
	\end{itemize}
	\item \textbf{Foreign Key Constraints}:
	\begin{itemize}
		\item \textbf{Foreign key}:   A foreign key refers to the primary key of a second relation (which can be itself)
		\item Each foreign key value must be the primary key value in the referenced relation or be null (foreign key constraint)
		\item  Also known as referential integrity constraints.
	\end{itemize}
\end{itemize}
\centerline{\includegraphics[width=1 \linewidth]{integrityconstraints}}
}

\section{2. SQL: Structured Query Language}
\begin{itemize}
\item  Declarative language: focus on what to compute, not on how to compute
\item Contains two parts: Data Definition Language and Data Manipulation Language
\end{itemize}
\subsubsection{Datatypes}
\centerline{\includegraphics[width=0.9 \linewidth]{datatypes}}

\subsection{Integrity Constraints 2}
\begin{itemize}
	\item A \textbf{consistent state} of the database is a state which complies with the with the business
		rules as defined by the structural constraints and the integrity constraints in the schema.
	\item If an integrity constraint is violated by an operation or a transaction, the operation or the transaction is aborted and rolled back and its changes are undone, otherwise, it is
		committed and its changes are effective for all users.
	\item Five main kinds of integrity constraints in SQL: \textbf{ NOT NULL, PRIMARY KEY, UNIQUE, FOREIGN KEY, CHECK.}
\end{itemize}
\subsubsection{Primary Key}
A primary key is a set of columns that uniquely identifies a record in the table. Each table has at most one primary key. The primary key can be one column or a combination of columns.

\begin{lstlisting}
-- Declare primary key as column constraint
CREATE TABLE customers (
 firstname VARCHAR(64  ,
 lastname VARCHAR(64) ,
 email VARCHAR(64) ,
id VARCHAR(16) PRIMARY KEY);
\end{lstlisting}
\subsubsection{Composite Primary Key \& NOT NULL }
A not null constraint guarantees that no value of the column can be set to null. A not null constraint is always declared as a row constraint. When it is explicit, it is declared with the keyword NOT NULL.
\begin{lstlisting}
CREATE TABLE games (
name VARCHAR(32) ,
version CHAR(3) ,
price NUMERIC NOT NULL,
PRIMARY KEY (name, version) );
\end{lstlisting}

\subsubsection{Data Insertion \ Populating Tables}
\begin{lstlisting}
INSERT INTO customers VALUES(
'Carole', 'Yoga', 'cyoga@email.org',
'Carole89');
\end{lstlisting}

\subsubsection{Deleting Tables}
\begin{lstlisting}
DELETE FROM customers
-- DROP deletes content \& table definition
DROP TABLE customers 
DROP TABLE IF EXISTS downloads  
\end{lstlisting}

\subsubsection{Unique}
A unique constraint on a column or a combination of columns guarantees the table cannot contain two records with the same value in the corresponding column or combination of columns.
\begin{lstlisting}
CREATE TABLE customers (
firstname VARCHAR(64) NOT NULL ,
lastname VARCHAR(64) NOT NULL,
email VARCHAR(64) UNIQUE NOT NULL,
id VARCHAR(16) PRIMARY KEY,
UNIQUE (firstname, lastname));
\end{lstlisting}

\subsubsection{Foreign Key}
\begin{itemize}
\item A foreign key constraint enforces \textbf{referential integrity}. The values in the columns for which the constraint is declared must exists in the corresponding columns of the referenced table.
\item Referenced columns are usually required to be the primary key of the referenced table. Some systems relax this.
\item A foreign key is declared using the keyword REFERENCES as a row constraint and the keywords FOREIGN KEY and REFERENCES as a table constraint.
\end{itemize}
\begin{lstlisting}
CREATE TABLE downloads (
customerid VARCHAR (16) REFERENCES customers (id),
name VARCHAR (32)
version CHAR (3),
FOREIGN KEY ( name, version) REFERENCES games (name, version) );
\end{lstlisting}

\subsubsection{Check}
\begin{itemize}
\item Check constraint enforces any other condition that can be expressed in SQL. Declared as row or table constraint. 
\end{itemize}
\begin{lstlisting}
CREATE TABLE games (
name VARCHAR(32),
version CHAR(3),
PRIMARY KEY (name, version)
price NUMERIC NOT NULL CHECK (price > 0)
-- or as table constraint:
CHECK (price > 0) );
\end{lstlisting}

\subsubsection{Update and Delete Propagation}
\begin{itemize}
\item The annotations ON UPDATE/DELETE with the option CASCADE propagate the update or deletion, when there are chains of foreign key dependencies.
\end{itemize}
\begin{lstlisting}
CREATE TABLE downloads(
id VARCHAR (16) REFERENCES customers (id)
	ON UPDATE CASCADE
	ON DELETE CASCADE,
name VARCHAR(32),
version CHAR(3),
PRIMARY KEY (id, name, version),
FOREIGN KEY (name, version) REFERENCES games(name, version)
	ON UPDATE CASCADE
	ON DELETE CASCADE);
\end{lstlisting}

\begin{itemize}
\item Generally a good idea to constraint all columns not to be null unless there is a good design or tuning reason for not doing so.
\item Think carefully about which foreign keys should be subject to cascade.
\item  Good idea to defer all the constraints that can be deferred. These are checked at the end of a transaction and not immediately after each.
operation.
\end{itemize}

\subsection{Querying Tables}
\subsubsection{Print Table}
• Wildcard '*' to include all attributes
\begin{lstlisting}
SELECT *
FROM customers;
\end{lstlisting}
\subsubsection{View}
	\begin{itemize}
		\item We can give a name to a query, called a view. Once created, a view can be queried like a table.
		\item Creating a view is generally a better option than creating and populating a table,
		temporary or not.
	\end{itemize}
\begin{lstlisting}
CREATE VIEW sg\_customers AS
SELECT  c.firstname, c.lastname, c.email, c.id
FROM customers c
WHERE country = 'Singapore';
\end{lstlisting}
\begin{lstlisting}
SELECT * FROM sg\_customers;
\end{lstlisting}



\section{3. SQL Queries}
\subsubsection{Printing one Table}
\begin{lstlisting}
SELECT firstname, lastname
FROM customers
WHERE country = 'Singapore';
\end{lstlisting}
\subsubsection{DISTINCT and ORDER BY}
• Selecting a subset of columns may result in duplicate row even if original table has a primary key. \\
• DISTINCT keyword eliminates eventual duplicates, requests results contain distinct rows. \\
• Both DISTINCT and ORDER BY involve sorting and conceptually ORDER BY is applied before SELECT DISTINCT.
\begin{lstlisting}
SELECT DISTINCT name, version 
FROM downloads
ORDER BY name ASC, version DESC;
\end{lstlisting}

\subsubsection{WHERE}
• Returns rows that evaluate to true, filter rows on a Boolean condition \\
• Uses Boolean operators such as AND, OR and NOT, and various comparison operators such as \code{>, <, >=, <=, <>, IN, LIKE} and \code{BETWEEN AND} \\
• Does not return rows that evaluate to unknown/null! \\
• '-' matches single char \\
• '\%' matches any sequence of zero or more chars
\begin{lstlisting}
SELECT firstname, lastname
FROM customers
WHERE country IN ('Singapore', 'Indonesia')
AND (dob BETWEEN '2001-01-01' AND '2000-12-01' OR since >= '2016-12-01 )
AND lastname LIKE 'B%'
\end{lstlisting}
• PostgreSQL use "||" for concatenation 
\begin{lstlisting}
-- Not to collect GST below 30 cents:
SELECT name || ' ' || version AS game, price * 1.07
FROM games
WHERE price * 0.07 < 0.3
\end{lstlisting}

\subsubsection{De Morgan's Laws}
\begin{lstlisting}
SELECT name 
FROM games
-- all 3 are the same:
WHERE (version = '1.0' or version = '1.1')
WHERE version IN ('1.0', '1.1')
WHERE NOT (version <> '1.0' AND version <> '1.1');
\end{lstlisting}
  
\subsubsection{NULL value}
• Every domain has additional value, null. Ambiguous, could be ”unknown”, ”does not exists”, or both. In SQL it is generally (but not always) ”unknown”. \\
• With null values, the logic of SQL is a three valued logic with unknown. \\
• Use \code{IS (NOT) NULL} for comparison with null \\
• \code{COALESCE()} returns the first non-null of its argument. \\
• \code{COUNT(*)} counts NULL values. \\
• \code{COUNT(att) AVG(att) MAX(att) MIN(att)} eliminate null values

\subsubsection{Cross Join}
• Cross join \& Cartesian Product \& cross product, represented by comma \code{CROSS JOIN} \code{,} \\
• Cross join with \code{WHERE} clause: add condition that FK columns equal to the corresponding PK columns. \\
• Systematically define table variables (e.g. \code{games AS g})
\begin{lstlisting}
SELECT *
FROM customers c, downloads d, games g
WHERE d.id = c.id
AND d.name = g.name
AND d.version = g.version
\end{lstlisting}

\section{4. Algebraic SQL Queries}
\subsubsection{Inner Join}
• \code{JOIN} interpreted as \code{INNER JOIN} 
• Inner joins combine records from two tables whenever there are matching values in a field common to both tables.
\begin{lstlisting}
SELECT *
FROM customers c JOIN downloads d ON d.id = c.id
JOIN games g ON d.name = g.name AND d.version = g.version;
\end{lstlisting}

\subsubsection{Natural Join}
•  If we give the same name to columns that are the same, can use natural join. Joins the rows that have the same values for their columns that have the same names. It also prints one of the two equated columns
\begin{lstlisting}
SELECT *
FROM customers c NATURAL JOIN downloads d NATURAL JOIN games g;
\end{lstlisting}

\vfill \null
\columnbreak

\subsubsection{Outer Join}
• outer join keeps the columns of the rows in the left (left outer join), right (right outer join) or in both (full outer join) tables that do not match anything in the other
table according to the join condition and pad the remaining columns with null values. \\
• Better to avoid outer joins whenever possible as they introduce null values. \\
• \code{RIGHT (OUTER) JOIN, LEFT (OUTER) JOIN} \\
• \code{ FULL (OUTER) JOIN} 
\begin{lstlisting}
-- finds customers, never downloaded a game
SELECT c.id FROM customers c 
LEFT JOIN downloads d ON c.id = d.id
WHERE d.id IS NULL;
\end{lstlisting}

\subsubsection{Set Operations}
• Union, intersect and non-symmetric difference. \\
• Eliminate duplicates: \code{UNION, INTERSECT, EXCEPT} \\
• Keep duplicates: \code{UNION ALL, INTERSECT ALL} \\
\code{EXCEPT ALL}

\section{4. Aggregate SQL Queries}
\subsubsection{Aggregate Functions}
• The values of a column can be aggregated aggregation functions such as \code{COUNT(), SUM(), MAX(), MIN()} \\
\code{AVG(), STDDEV()} etc.
\begin{lstlisting}
SELECT COUNT(*) 
FROM customers c;
\end{lstlisting}

\begin{lstlisting}
-- ALL is default and omitted
-- DISTINCT needed 
SELECT COUNT(ALL DISTINCT c.country) 
FROM customers c;
\end{lstlisting}

\begin{lstlisting}
-- Finds min, max, avg and stddev, TRUNC() displays 2 d p
SELECT MAX(g.price),
MIN(g.price),
TRUNC(AVG(g.price), 2) AS ave,
TRUNC(STDDEV(g.price), 2) AS std
FROM games g;
\end{lstlisting}

\subsubsection{Group By}
• The GROUP BY clause creates groups of records that have the same values for the
specified fields before computing the aggregate functions. \\
• Groups are formed after the rows have been filtered by the WHERE clause \\
• Recommended (and required by SQL standard) to include attributes projected in the SELECT clause in the GROUP BY clause. \\
• The order of columns in the GROUP BY clause does not change the meaning of the query.
\begin{lstlisting}
SELECT c.country, COUNT(*)
FROM customers c
WHERE c.dob >= '2000-01-01'
GROUP BY c.country
\end{lstlisting}

\begin{lstlisting}
SELECT c.country, EXTRACT( YEAR FROM c.since) AS regyear, COUNT(*) AS total
FROM customers c, downloads d
WHERE c.id = d.id
GROUP BY c.country, regyear,
ORDERBY regyear, c.country;
\end{lstlisting}

\subsubsection{Having}
• Aggregate functions can be used in conditions. However, agg. functions not allowed in WHERE. \\
• \code{HAVING} clause to add conditions to be checked after the evaluation of the GROUP BY. \\
• \code{HAVING} can only involve aggregate functions, columns listed in the GROUP BY clause and subqueries.

\begin{lstlisting}
SELECT c.country, 
FROM customers c
GROUP BY c.country
HAVING COUNT(*) >= 100;
\end{lstlisting}

\vfill \null
\columnbreak

\section{5. Nested SQL Queries}
\subsubsection{Subqueries}
• In FROM clause: Must be enclosed in parenthesis, Table alias mandatory, Column aliases optional \\
• Not recommended, can be written as simple query
\begin{lstlisting}
SELECT cs.lastname, d.name
FROM (SELECT * 
	 FROM customers c
	WHERE c.country = 'Singapore') AS cs, downloads d
WHERE cs.id = d.id;
\end{lstlisting}
• In WHERE clause, also can be written as simple query. \\
• Never use a comparison to a subquery without specifiying the quantifier ALL or ANY
\begin{lstlisting}
SELECT g1.name, g1.version, g1.price
FROM games g1
WHERE g1.price >= ALL (
	SELECT g2.price
	FROM games g2);
-- or do:
WHERE g1.price = ALL (
	SELECT MAX(g2.price)
	FROM games g2);
-- Note HAVING g.price=MAX(g.price) will not work
\end{lstlisting}


\subsubsection{Exists}
• \code{EXISTS} evaluates to true if the subquery has some results. \\
•  Generally correlated. If uncorrelated, likely unnecessary.
\begin{lstlisting}
SELECT c.id FROM customers c
WHERE NOT EXISTS (
	SELECT d.id
	FROM downloads d
	WHERE c.id = d.id);
-- same as
WHERE c.id NOT IN (
	SELECT d.id 
	FROM downloads d);
-- same as
WHERE c.id <> ALL (
	SELECT d.id 
	FROM downloads d);
\end{lstlisting}

\begin{lstlisting}
-- Find countries with most customers
SELECT c1.country
FROM customers c1
GROUP BY c1.country
HAVING COUNT(*) >= ALL (
	SELECT COUNT(*)
	FROM customers c2
	GROUP BY c2.country);
\end{lstlisting}

\subsubsection{SQL Conditionals}
\textbf{CASE expression}
• Generic conditional, like if/else statement, Used in SELECT, ORDER BY, etc
\begin{lstlisting}
-- Regular if else
CASE	
	WHEN cond1 then res1
	WHEN cond2 then res2
	...
	WHEN condN then resN
	ELSE res0
END
\end{lstlisting}
\begin{lstlisting}
-- Switch like statement
CASE expression
	WHEN val1 then res1
	WHEN val2 then res2
	...
	WHEN valN then resN
	ELSE res0
END
\end{lstlisting}

\subsubsection{Conceptual evaluation of queries} 
FROM $\rightarrow$ WHERE $\rightarrow$ GROUP BY $\rightarrow$ HAVING $\rightarrow$ SELECT $\rightarrow$
ORDER BY $\rightarrow$ LIMIT/OFFSET

\vfill \null
\columnbreak

\section{6. ER Model}
Data Modeling Using the Entity-Relationship (ER) Model
\centerline{\includegraphics[width=0.9 \linewidth]{ernotation}}

\subsubsection{Entity}
• Objects that are distinguishable from other objects \\
• \textbf{Entity set:} Collection of entities of the same type \\
• In ER diagrams, an entity type is displayed in a rectangular box

\subsubsection{Attributes}
• \textbf{Attributes} are properties used to describe an entity \\
• Each attribute has a value set (or data type) associated with it – e.g. integer \\
• \textbf{Key attribute(s)} uniquely identifies each entity \\
• \textbf{Composite attribute} composed of multiple other attributes \\
•  \textbf{Multivalued attribute} may consist of more than one value for a given entity \\
• \textbf{Derived attribute} derived from other attributes
\centerline{\includegraphics[width=0.8 \linewidth]{attributes}}
• Attributes are displayed in ovals, multivalued attributes double ovals

\subsubsection{Relationship}
• \textbf{A relationship} relates two or more distinct entities with a specific meaning. \\
• \textbf{Degree} of a relationship type is the number of participating entity types. A n-ary relationship set involves n entity roles. Typically binary or ternary. \\ 
\centerline{\includegraphics[width=0.8 \linewidth]{n-ary}}
• \textbf{Relationship Set}: Collection of relationships of the same type, can have their own attributes that further decribe the relationship \\
• Most \textbf{relationship attributes} are used with M:N relationships: (In 1:N relationships, they can be transferred to the entity type on the N-side of the relationship) \\
• We represent the relationship type as \textbf{Diamond-shaped box}, connected to the participating entity types. \\
• Relationship type typically readable from left to right and top to bottom.

\subsubsection{N-ary relationships}
• \textbf{Implicit Constraint} In ternary relationship, every instance of relationship must have one instance of each entity. \\
• Rule extends to n-ary relationships \\
\centerline{\includegraphics[width=0.7 \linewidth]{ternary}}
• \textbf{Avoid Ternaries for Easy Modeling}: e.g.  “objectifying” the relationship type “Interview” into an entity type ‘Interview”. 


\subsubsection{Cardinality (Ratio) constraints}
• \textbf{Upper bound} for entity’s participation \\
\centerline{\includegraphics[width=0.7 \linewidth]{cardinality}}

\subsubsection{Participation / Existence Dependency constraints}
• \textbf{Lower bound} for entity’s participation \\
• Partial (default): participation not mandatory \\
• Total: mandatory (at least 1) \\
\centerline{\includegraphics[width=0.8 \linewidth]{participation}}

\subsubsection{Recursive Relationship Type}
• A relationship type between the same participating entity type in \textbf{distinct roles}. \\
• In ER diagram, need to display role names to distinguish participations.

\subsubsection{Dependency constraints}
\textbf{Weak Entity Types}: No key attribute and is identification dependent on another entity. \\
• Participate in an identifying relationship type with an owner or identifying entity type \\
• Two kinds of dependencies: \\
 \textbf{Existence (no weak entity)} dependency\\
 \textbf{Identification (weak entity)} dependency \\
\textbf{Partial Key} \\
•  Set of attributes of weak entity set that uniquely identifies a weak entity, for a given owner entity. \\
\centerline{\includegraphics[width=0.8 \linewidth]{partialkey}}

\subsubsection{(min,max) notation for relationship constraints}
• Read the min,max numbers next to the entity type and looking away from the entity type \\
\centerline{\includegraphics[width=0.8 \linewidth]{minmax}}

\section{7. EER Model}
\textbf{Enhanced ER or Extended ER}

\subsubsection{IS-A Hierarchies}
• \textbf{“Is a” relationship} - used to model generalization/specialization of entity sets. \\
• \textbf{Hierarchy}: constraint that every subclass has only one superclass (single inheritance); basically a tree structure. \\
• \textbf{Lattice}: a subclass can be subclass of more than one superclass (multiple inheritance). \\
\centerline{\includegraphics[width= 1\linewidth]{lattice}}
• \textbf{Subclass:} subclass member is entity in a \textbf{distinct specific role}. Entity inherits all attributes and relationships of superclass. \\
• \textbf{Specialization:} process of defining a set of subclasses of a superclass, based on \textbf{distinguishing characteristics} \\
• \textbf{Type of Specialization:} Can be Predicated defined, Attribute defined (Written beside joining line) or User defined. \\
• \textbf{Generalization:} reverse of specialization, based upon some \textbf{distinguishing characteristics}. \\

\subsubsection{Constraints on Specialization / Gen}
• \textbf{Disjointness Constraint:} Subclasses must be disjoint, entity can be member of at most one. (specified by \textbf{d} in EER) \\ 
• If not disjoint, specialization is \textbf{overlapping}, (specified by \textbf{o} in EER) \\
• \textbf{Completeness Constraint:} Total specifies every entity must be a member of some subclass. (specified by \textbf{double line} in EER) \\ 
• \textbf{Partial} allows entity not to belong to any subclass. (specified by \textbf{single line} in EER) \\ 
• Hence, we have four types: Disjoint/Overlapping x Total/Partial. Note generalization usually is total.

\vfill\null
\columnbreak

\section{8. Relational Mapping}
• Preserve info, maintain constraints, minimize null.

\subsubsection{1. Map Regular Entity Types}
• Create new table (relation R), include all simple attributes.
\subsubsection{2. Map Weak Entity Types}
• Weak entity type, create table with corresponding FK.
\subsubsection{3. Map Binary 1:1 Relationship Type}
• Option 1: 2 Foreign Key (2 relations \ tables) option. \\
• 2: Merged relation option: Combine relationship set and either entity set into \textbf{one} table \\
• 3: Cross-reference (3 relations, one lookup table). 
\subsubsection{4. Map Binary 1:N Relationship Type}
• For 1:N create table of participating entity (N-side). \\
• Include FK in table \& attributes of the 1:N relation type. \\
\centerline{\includegraphics[width=0.6 \linewidth]{onetomany}}
\subsubsection{5. Map Binary N:M Relationship Type}
• Represent relationship set with a new table. Include as FK the PK of relations, combination will form PK of table.
\subsubsection{6. Map Multi-valued Attributes}
• Create new table / relation for each multivalued attribute.
\subsubsection{7. Map N-ary relationship type}
• For each n-ary relationship type R, where n $>$2, create new table. Include FK of relations, and attributes. \\
\textbf{Summary:} \\
\centerline{\includegraphics[width=0.9 \linewidth]{mapsummary}}
\subsubsection{8. Map Specialization or Generalization}
• Option 1: Multiple tables (relations) - Superclass and subclasses \\
• 2: Table each for each subclass relations, inherit superclass attributes\\
• 3: Single table with one type attribute \\
• 4: Single table with multiple type attributes \\
• For specialisation hierarchies with one superclass and n subclasses, possibility of mapping from 1 relation 
to (n+1) relations. Design highly subjective, try to maintain appropriate attributes to determine subclass identity.

\vfill\null
\columnbreak

\vfill\null
\columnbreak

\section{9. Relational Calculus \& Algebra}
\begin{itemize}
\item Both are formal query languages. A query is composed of a collection of operators called relational operators.
\item \textbf{Relational Calculus} (declarative language: what is to be done rather than how to do it). Order not specified, concerned with result we have to obtain. 
\item \textbf{Relational Algebra}: (procedural language) Order specified in which operations have to be performed.
\item Relational algebra basis of implementation of relational DBMS.
\item SQL queries translated into execution plans, orchestrate physical implementation of relational algebra operators.
\end{itemize}

\subsubsection{Predicate Logic}
\begin{itemize}
\item \textbf{Predicate / first order logic}: formulae built from:
\item \textbf{predicates} (lowercase) , \textbf{operators} ($=$, etc.) \textbf{constants} (lower case), \textbf{variables} (upper case, quantified or free), \textbf{connectives} ($\rightarrow $), and \textbf{quantifiers} ($\forall$ and $\exists$).
\item \textbf{Existential quantifier}, $\exists$: disjunction: \smallskip \\
\centerline{ $ \exists X, F[X] \equiv F[a] \vee F[b] \vee ... $  }
\item \textbf{The universal quantifier}, $forall$: conjunction. \smallskip \\ 
\centerline{ $ \forall X, F[X] \equiv F[a] \wedge F[b] \wedge ... $  }
\item \textbf{De Morgan laws} applies to quantifiers. \medskip \\ 
\centerline{ $ \neg(\exists X, F[X]) \equiv \forall X, \neg F[X]  $  } \\
\centerline{ $ \neg(\forall X, F[X]) \equiv \exists X, \neg F[X]  $  }
\end{itemize}


\section{Relational Calculus (Tuple)}
\begin{itemize}
\item Concerned with \textbf{result we have to obtain}.
\item In \textbf{Tuple Relation Calculus (TRC)} variables values of rows of tables (t-uples.), is the theoretical basis of SQL. 
\item \textbf{Material Implication:} $P \rightarrow Q \equiv \neg P \vee Q$
\item \textbf{Relational Calculus denoted as:} \medskip \\
\centerline{$\{ t  |  P(t)  \}$}
\item \textbf{t}: set of tuples, \textbf{P}: condition which is true for the given set of tuples. 
\item E.g. $\{T | \exists T1 (T1 \in$ department $\wedge$ T1.faculty $=$ 'School of Computing' $\wedge T$.department =
T1.department)$\}$
\end{itemize}

% \vfill \null
\columnbreak



\section{Relational Algebra}
\begin{itemize}
\item Order is specified in which operations have to be performed.
\end{itemize}

\subsubsection{Unary Operators}

\subsubsection{\underline{Selection}, $\sigma _c$}
\begin{itemize}
\item For each tuple $T \in R, T \in \sigma_c(R)$, means selection condition \textbf{c} evaluates to true for tuple t.
\item E.g. Find the customers from Singapore. \smallskip \\
\centerline{$ \sigma_{c.country = `Singapore'}(\rho(customers, c)) $}
\item Equivalent to:
\begin{lstlisting}
SELECT * FROM customers c
WHERE c.country = `Singapore'
\end{lstlisting}

\item \textbf{Condition} is boolean expression of form:

        \vspace{-0.5cm}
        \begin{center}
          \resizebox{\hsize}{!}{%
            \begin{tabular}{ |c|c| }
              \hline
              expression & example \\ \hline
              attribute \textbf{op} constant & $\sigma_{\text{start}=2020}(\text{Projects})$ \\ \hline
              $attr_1$ \textbf{op} $attr_2$ & $\sigma_{\text{start}=\text{end}}(\text{Projects})$ \\ \hline
              $expr_1 \land expr_2$ & $\sigma_{\text{start}=2020 \,\land\, \text{end}=2021}(\text{Projects})$ \\ \hline
              $expr_1 \lor expr_2$ & $\sigma_{\text{start}=2020 \,\lor\, \text{end}=2021}(\text{Projects})$ \\ \hline
              $\neg \, expr$ & $\sigma_{\neg(\text{start}=2020)}(\text{Projects})$ \\ \hline
              $(expr)$ & - \\ \hline
            \end{tabular}
          }
        \end{center}
        \vspace{-0.4cm}

\bigskip

\item \textbf{op} $\in \{ =, <>, <, \leq, \geq, > \}$
\item Precedence: $(), \textbf{op}, \neg, \land, \lor$
\item \textbf{null} comparison is \textbf{unknown}, arithmetic with \textbf{null} is \textbf{null}

\end{itemize}


\subsubsection{\underline{Projection} $\pi_l$}
\begin{itemize}
\item Projects columns of a table specified in \textbf{list $l$}. 
\item \code{(SELECT xx, yy FROM games)} 
\item \textbf{Order of attribute in $l$} matters.
\item Duplicates removed. 
\item \textbf{Examples:}  \smallskip \\
\centerline{$ \pi_{g.name, g.version, g.price}(\rho(games, g)) $}

 \mbox{} \\
        \begin{minipage}{0.575 \columnwidth}
          \begin{center}
            Teams \\
            \begin{tabular}{ |c|c|c| }
              \hline
              \textbf{en} & \textbf{pn} & \textbf{hours} \\ \hline
              Sarah & BigAI & 10 \\ \hline
              Sam & BigAI & 5 \\ \hline
              Sam & BigAI & 3 \\ \hline
            \end{tabular}
          \end{center}
        \end{minipage}
        \hfill
        \begin{minipage}{0.4 \columnwidth}
          \begin{center}
            $\pi_{\text{pn}, \text{en}}(\text{Teams})$ \\
            \begin{tabular}{ |c|c|c| }
              \hline
              \textbf{pn} & \textbf{en} \\ \hline
              BigAI & Sarah \\ \hline
              BigAI & Sam \\ \hline
            \end{tabular}
          \end{center}
        \end{minipage}

\end{itemize}

\columnbreak

\subsubsection{\underline{Renaming}, $\rho_l$}
\begin{itemize}
\item Can change name of relation, of attributes, or both.
\item {Change name of relation: $ \rho(R_1, R_2) $}  
\item {Change attribute names:  {$ \rho(R_1, R_1(a_1 \rightarrow b_1, a_2 \rightarrow b_2)) $}}
\end{itemize}

\subsubsection{Set Operations}
\begin{itemize}
\item Set operations include $\cup, \cap, \times $, set difference ($\setminus$)
\item Intersection able to express with union and set difference:  \\
\centerline{$  R \cap S = (R \cup S) - ((R-S) \cup (S-R)) $}
\item \textbf{Union Compatability}: two relations must be union compatible. Have same number of attributes, 
corresponding attributes have same or compatible domains. 
\item (i.e. relations must have same columns).

\item \textbf{Cross Product}: (Cartesian Product) Forms all possible pairs of tuples from two relations. \\
\centerline{ $  R_1 \times R_2  $}

\end{itemize}

\subsubsection{Join Operations}
\begin{itemize}
\item  Combines $ \times, \sigma_c, \pi_l$ into a single op.
\item Simple relational algebra expressions
\end{itemize}

\subsubsection{\underline{Inner Joins}}
\begin{itemize}
\item  Eliminates tuples that do not satisfy matching
criteria (i.e. selection)
\item Is a selection from cross product \\
\centerline{  R $\Join_C$ S = $\sigma_C$ (R $\times$ S) }
\item Example: \\
\centerline{$ \rho(customers, c) \Join_{d.id = c.id} \rho(downloads, d) $}
\end{itemize}

\subsubsection{Relational Calculus \& Algebra}
\begin{itemize}
\item \textbf{4 Steps to construct calculus and algebra queries:} \\
1) Construct SQL query you are familiar with (difficult) \\
2) From query, map the tables that you need (yellow) \\
3) From query, map the conditional statements (blue) \\ 
4) From query, map the columns you need to print (green) \\
\centerline{\includegraphics[width=1 \linewidth]{RAexample}}
\end{itemize}

\section{10. Programming with SQL}
\subsubsection{Writing Database Applications}
\begin{itemize}
\item \textbf{Interactive SQL}: Directly writing SQL statements to an interface. (e.g. PostgreSQL's psql cli, pgAdmin).
\item \textbf{Non-interactive SQL:} SQL statements included in application written in host language. 
\item 2 Main alternatives: \textbf{Statement Level Interface (SLI), and Call Level Interface (CLI).}
\item Crudely, SLI = CLI in disguise, as SLI preprocessor generates CLI code.
\end{itemize}

\subsubsection{Statement Level Interface (SLI)}
\begin{itemize}
\item Code is mix of host language statements and SQL statements (e.g. embedded SQL, dynmaic SQL).
\item \textbf{Basic process for SLI}: Write code that mixes host langugae with SQL, preprocess code using a preprocessor, compile code into exe program.
\end{itemize}
\medskip
\centerline{\includegraphics[width=0.7 \linewidth]{sli}}

\subsubsection{Call Level Interface (CLI)}
\begin{itemize}
\item Application completely written in host language, while \textbf{SQL statements are strings} passed as \textbf{arguments} to host language procedures or libraries
\item E.g. ODBC (Open DataBase Connectivity), JDBC (Java DB Connectivity), psycopg library for Python - PostgreSQL.
\end{itemize}
\bigskip
\centerline{\includegraphics[width=0.9 \linewidth]{cli}}
\bigskip

\subsubsection{SQL Injection Attack}
\begin{itemize}
\item Class of cyber attacks on dynamic SQL, goal is to execute unintended (malicious) SQL statements.
\item \textbf{Typical cause}: dynamic queries are generated by merging / concatenating strings.
\item \textbf{Common attack point}: Omnipresent form fields in web interfaces. Entered values define some SQL statement.
\item \textbf{Key Points}: Don't manually merge values to a query, don't use \% or $+$ operator to merge values, use provided methods. 
\end{itemize}

\vfill \null
\columnbreak


\section{11. SQL Functions and Procedures}
\begin{itemize}
\item Tasks \textbf{requiring multiple DB operations} common, involve any combination of reads and writes. 
\item E.g. update user password: check user exists $\rightarrow$ check new password differs from old $\rightarrow$ if ok, update password (3 separate requests/accesses to DB)
\item \textbf{Problems}: Application and DB may run on different machines, poor performance or DB becomes bottleneck. 
\item Different DB operations only loosely connected, difficult to ensure ``all or nothing'' behavior.
\item \textbf{Approach:} Move (some) application logic into DB, group DB operations that form task together, treat task as single DB operation.
 \end{itemize}

\bigskip


\subsubsection{11. Stored Functions and Procedures}
\begin{itemize}
\item \textbf{Collection of SQL statements and procedural logic}, precompiled and reusable code, allows execute multiple database operations as a single unit.
\item \textbf{Procedural Logic:} Relevant for application logic that requires assignments, conditionals or loops, and queries that cannot be expressed using basic SQL.
\item \textbf{ISO standard:} SQL/PSM (Persistent Stored Modules). Different DBMS have their own flavor.
\item \textbf{Advantages:} better performance, code reuse, ease of maintenance, added security.
\item \textbf{Disadvantages:} testing \& debugging more challenging, limited portability / vendor lock in, no simple versioning of code, not the most intuitive language.
 \end{itemize}
 
 \vfill \null
 \columnbreak
\section{Stored Functions, Procedures}
\centerline{\includegraphics[width=1\linewidth]{functionbasicsyntax}}
\begin{itemize}
        \item \code{CREATE OR REPLACE} helps to re-declare function/procedure if already previously defined
        \item Code is enclosed within \code{\$\$ <> \$\$}
        \item Calling a function: (USE SELECT, e.g.) \\
        \code{SELECT * FROM swap(2, 3);}
        \item Call a procedure: (USE CALL, e.g.) \\
        \code{CALL transfer( 'Alice', 'Bob', 100);}
\end{itemize}

\centerline{\includegraphics[width=1 \linewidth]{storedprocedures}}
\begin{itemize}
\item Syntax essentially same for procedures and functions, but procedures invoked using CALL command.
\item \textbf{Obvious Difference}: Procedures no RETURNS clauses.
\item \textbf{Functions} must return something (but can be VOID).
\item \textbf{Procedures} do not have to return anything, but can (using INOUT and OUT params).
\end{itemize}

\subsubsection{Function Arguments for Functions}
\begin{itemize}
\item \textbf{Each argument described by 3 values}
\item \textbf{Mode}: of argument (mainly IN, OUT, INOUT)
\item \textbf{Name}: of argument (optional)
\item \textbf{Type}: datatype of argument. (e.g. INT, VARCHAR) 
\end{itemize}
\centerline{\includegraphics[width=1 \linewidth]{functionargument}}

\subsubsection{sql VS plpsql}
\begin{itemize}
\item \textbf{sql:} Use where body consists of only SQL statements, often a wrapper of single / few SQL statments. Simpler syntax, no \{BEGIN ... END\}
\item \textbf{PL/pgSQL:} Procedural Lang/ PostgreSQL, allows writing of procedural code providing control flows, variables, error handling. Statements generated at runtime, used for trigger functions.
\end{itemize}

\textbf{Function}
\begin{lstlisting}
CREATE OR REPLACE FUNCTION swap 
    (INOUT val1 INT, INOUT val2 INT)
RETURNS RECORD AS $$
DECLARE
  temp INT;
BEGIN
  temp := val1;  val1 := val2; val2 := temp;
END;
$$ LANGUAGE plpgsql;
\end{lstlisting} 

\textbf{Procedure}
\begin{lstlisting}
CREATE OR REPLACE PROCEDURE transfer 
    (src TEXT, dst TEXT, amt NUMERIC) 
AS $$
  UPDATE Accounts
  SET bal = bal - amt WHERE name = src;
  UPDATE Accounts
  SET bal = bal + amt WHERE name = dst;
$$ LANGUAGE sql;
\end{lstlisting}



\subsubsection{Return and Type}
\centerline{\includegraphics[width=0.8 \linewidth]{tuple}}
    \begin{center}
      \begin{tabular}{ |c|c| }
        \hline
        \textbf{Return} & \textbf{Type} \\ \hline
        \makecell{One existing tuple \\ from table} & \code{<table_name>} \\ \hline
        \makecell{Set of tuples \\ from table} & \code{SETOF <table_name>} \\ \hline
        Single new tuple & \code{RECORD} \\ \hline
        Set of new tuples & \makecell{ \code{SETOF RECORD} or \\ \code{TABLE(attributes...)} } \\ \hline
        No return value & \makecell{ \code{VOID}, or use \code{PROCEDURE} \\ instead of \code{FUNCTION} } \\ \hline
        Trigger & \code{TRIGGER} \\ \hline
      \end{tabular}
    \end{center}
Important: If we use RECORD, we must have at least two OUT parameters. But if we use TABLE construct, we can just have one attribute.

\subsubsection{Stored Functions vs. Procedures}
\begin{itemize}
\item Procedures can \textbf{commit or roll back transactions} during execution, cannot be involved in DML commands (select, insert, update, delete).
\item Procedures invoked in isolation using \code{CALL}, functions invoked in \code{SELECT} statements.
\item \textbf{Best practice}: return value(s): create function, no return value: create procedure.
\end{itemize}

\subsubsection{Assignments (of values of variables)}
\begin{itemize}
\item \textbf{Basic Assignment} with \code{:=}, e.g. \code{age := 29;}
\item \textbf{Assignment of query result} to declared variable(s): \code{SELECT ... INTO ...}
\end{itemize}
\begin{lstlisting}
SELECT points INTO mark 
FROM students WHERE id = sid;
\end{lstlisting}

\centerline{\includegraphics[width=1 \linewidth]{controlstructures}}
\smallskip
\begin{itemize}
\item No curly braces or colons, hence additionaly keywords to indicate where loop begins and ends.
\item \code{END IF} for conditionals, \code{END LOOP} for loops.
\item \textbf{Simple example}: Compute sum of first n integers, if n is negative, return 0.
\end{itemize}

\begin{lstlisting}
CREATE FUNCTION sum_n(IN n INT)
RETURNS INT AS $$
DECLARE  sum INT;
BEGIN
    sum := 0;
    IF n <= 0 THEN 
        RETURN sum; 
    END IF;
    FOR val IN 1..n 
    LOOP
        sum := sum + val;
    END LOOP;
    RETURN sum;
END; $$
LANGUAGE plpgsql;
SELECT * FROM sum_n(5);
\end{lstlisting}

We can also raise an exception if n is negative:
\begin{lstlisting}
    IF n <= 0 THEN 
        RAISE EXCEPTION 'n<0 error' ; 
    END IF;
\end{lstlisting}

\subsubsection{Errors \& Messages}
\begin{itemize}
\item \code{RAISE} keyword. 6 raise levels in PostgreSQL.
\end{itemize}
\centerline{\includegraphics[width=0.9 \linewidth]{raise}}

\subsubsection{Loop Use Case: Loop through Query Results}
\begin{itemize}
\item Special FOR loop to iterate through results and manipulate data. (Common use case).
\item $<target>$: Record or row variable that is successively assigned each row from query.
\item $<statements>$: List of stmts using current target row.
\end{itemize}
\centerline{\includegraphics[width=0.6 \linewidth]{queryForLoop}}

\begin{lstlisting}
CREATE FUNCTION compute_points_gaps()
RETURNS TABLE(
    name TEXT, points INT, gap INT) AS $$
DECLARE  
    s RECORD; prev INT:= -1;
BEGIN
    FOR s IN SELECT * 
        FROM students ORDER BY points DESC
    LOOP
        name := s.name;
        points := s.points;
        IF prev >= 0 THEN
             gap := prev - s.points;
        ELSE
            gap := 0;
        END IF;
        RETURN NEXT; -- (OUTPUT) TABLE TUPLE
        prev := s.points;
    END LOOP;
END; $$
LANGUAGE plpgsql;
\end{lstlisting}


\subsubsection{Cursors}
\begin{itemize}
\item  \textbf{Purpose}: Declare on a query, access each indiv row. 
\item Helps avoids memory overrun when the query result is large (don't access whole query at once). \\
\centerline{\includegraphics[width=1 \linewidth]{cursorworkflow}}
\end{itemize}
\begin{lstlisting}
CREATE FUNCTION compute_points_gaps()
RETURNS TABLE(
    name TEXT, points INT, gap INT) AS $$
DECLARE
    c CURSOR FOR (SELECT * FROM students ORDER BY points DESC);
    s RECORD; prev INT;
BEGIN
    prev := -1;
    OPEN c;
    LOOP
        FETCH c INTO s;
        EXIT WHEN NOT FOUND;
        name := s.name;
        points := s.points;
        IF prev >= 0 THEN
            gap := prev - s.points;
        ELSE
            gap := 0;
        END IF;
        RETURN NEXT; -- (OUTPUT) TABLE TUPLE
        prev := s.points;
    END LOOP;
    CLOSE c;
END; $$
LANGUAGE plpgsql;
-- ** To check NULL: IF high IS NULL THEN, not IF high = NULL THEN
\end{lstlisting}

\textbf{Advantage of Cursor (over for loops etc.)}:

\begin{itemize}
	\item Flexible `navigation' through query results in \textbf{different directions}.
	\item \code{FETCH} to move row and read data.
	\item \code{MOVE} only to move to row (no read).
\end{itemize}

\subsubsection{Cursor Directions}
\centerline{\includegraphics[width=1 \linewidth]{cursordirections}}
\subsubsection{Examples}
\begin{itemize}
\item Using FETCH ABSOLUTE, FETCH NEXT, FETCH RELATIVE to calculate median points().
\item \textbf{Dynamic cursors}: Cursors can also have inputs, which are taken from function inputs, that affect the query results. 
\item SELECT median\_points(TRUE); \\
vs SELECT median\_points(FALSE);
\end{itemize}
\medskip
\centerline{\includegraphics[width=1 \linewidth]{cursorex}}
\bigskip
\centerline{\includegraphics[width=1 \linewidth]{cursorex2}}


\section{12. Triggers}
\subsubsection{Motivation}
\begin{itemize}
	\item \textbf{Model constraints}, where user is not forced to call stored procedure or funtion.
	\item Example constraints: restricted change in data, derived values, set cardinality constraints.
	\item \textbf{Application Requirement}: E.g. automatic logging of changes.
	\item We could create a stored procedure that combines insertion and logging, but users can circumvent this by directly running \code{INSERT INTO} instead of calling procedure.
\end{itemize}

\subsubsection{Trigger Concept (Trigger fires Trigger Function)}
\begin{itemize}
	\item Triggers has \textbf{Event-Condition-Action} rule.
	\item When event occurs, test condition, and if satisifed, perform action.
	\item \textbf{ECA rule} is split into 2 parts: \\ 
	Event and Condition under \textbf{Trigger}, and \\
	Action under \textbf{Trigger Function}.
\end{itemize}
\smallskip
\centerline{\includegraphics[width=1 \linewidth]{triggerfunction}}

\columnbreak 

\subsection{Triggers}
\begin{itemize}
\item Triggers can listen on multiple event types.
\end{itemize}

\begin{lstlisting}
CREATE TRIGGER 
    on_student_modified_advanced
AFTER INSERT OR DELETE OR UPDATE ON students
FOR EACH ROW
EXECUTE FUNCTION log_student_advanced();
\end{lstlisting}

\begin{itemize}
\item Triggers options: \textbf{Event, Timing, Granularity.}
\item \textbf{Event}: Situation that fires trigger.
\item \textbf{Timing}: When trigger is fired (BEFORE or AFTER) for tables, (INSTEAD OF) for views.
\item \textbf{Granularity}: Specifies if triggered for each affect row or only once. (FOR EACH ROW / F.E. STATEMENT)
\end{itemize}

\centerline{\includegraphics[width=0.9 \linewidth]{triggerevents}}
\centerline{\includegraphics[width=1 \linewidth]{triggertiming}}

\subsubsection{Views (Recap) and Triggers}
\begin{itemize}
\item \textbf{Views}: virtual table, a permanently named query.
\item Query results not permanently stored, executed each time query used, hides complexity, heavily used.
\end{itemize}
\begin{lstlisting}
CREATE VIEW <name> AS
    SELECT ... FROM ... ...;
\end{lstlisting}
\begin{itemize}
\item \textbf{Updateable Views}: Must have only one entry in FROM clause, no GROUP BY / LIMIT  etc, no UNION, INTERSECT, no aggregate functions. Otherwise direct modification not possible.
\item Triggers useful for (non-updateable) views. \\
 \textbf{(Trigger Timing: (INSTEAD OF) for views.)}
\end{itemize}

\centerline{\includegraphics[width=1 \linewidth]{triggergranularity}}

\subsection{Trigger Conditions }
\begin{itemize}
\item Execute trigger function only if condition is true.
\item Instead of having condition in trigger function, we move to trigger, and only execute if condition is true.
\item \textbf{Condition}: generally can formulate any boolean expression, but no SELECT, OLD for INSERT, NEW for DELETE, in the WHEN() clause.
\end{itemize}
\smallskip
\begin{lstlisting}
CREATE TRIGGER on_student_updated_advanced
AFTER UPDATE ON students
FOR EACH ROW WHEN (NEW.points <> OLD.points)
EXECUTE FUNCTION log_student_advanced();
\end{lstlisting}

\subsection{Deferrable Triggers}
\begin{itemize}
\item Triggers run immediately for every statement that fire them.
\item Operations of multiple statements yielding intermediate inconsistent states
\item \textbf{Deferred triggers}: Run trigger only at end of transactions.
\end{itemize}

\begin{lstlisting}
CREATE CONSTRAINT TRIGGER on_account_modified
AFTER INSERT OR DELETE OR UPDATE ON accounts
DEFERRABLE INITIALLY IMMEDIATE
FOR EACH ROW
EXECUTE FUNCTION check_balance();
\end{lstlisting}

\begin{itemize}
\item Only work for AFTER and FOR EACH ROW triggers.
\item Both CONSTRAINT and DEFERRABLE must be specified.
\item INITIALLY DEFERRED: trigger deferred by default.
\item INITIALLY IMMEDIATE: trigger not deferred by default (but can be deferred on demand).
\end{itemize}

\columnbreak 

\begin{lstlisting}
BEGIN TRANSACTION;
SET CONSTRAINTS on_account_modified DEFERRED;
UPDATE accounts SET balance = balance - 50 WHERE id = 10;
UPDATE accounts SET balance = balance + 50 WHERE id = 11;
END TRANSACTION;
\end{lstlisting}

\subsection{Other Trigger Notes}
\begin{itemize}
\item \textbf{Trigger Order}: Triggers for same event on same table:
\item Order of activation: BEFORE statement-level, BEFORE row-level, AFTER row-level, AFTER statement-level.
\item Within each, fired in alphabetic order. If BEFORE row-level trigger returns NULL, subsequent triggers on same row omitted.
\end{itemize}


\subsection{Trigger Functions}
\begin{itemize}
	\item Trigger functions do not take in (ordinary) arguments.
	\item Must have return type TRIGGER
	\item Must be defined before trigger itself.
	\item \textbf{``Input''}: Special internal data structure from trigger.
\end{itemize}

\subsubsection{Useful Data available in trigger function}
\begin{itemize}
\item When function is called as a trigger, several special variables created automatically in top level block.
\end{itemize}
\centerline{\includegraphics[width=0.9 \linewidth]{tgdata}}

\subsubsection{Trigger Function Example}
\begin{itemize}
\item Schema:  advanced\_logs(student: INT, operation: TEXT, p\_old: INT, p\_new: INT, created\_at: TIMESTAMP)
\item Log all events that might modify students' points (INSERT, UPDATE, DELETE)
\end{itemize}

\begin{lstlisting}
CREATE OR REPLACE FUNCTION log_student_advanced()
RETURNS TRIGGER AS $$ BEGIN
    IF TG_OP = 'INSERT' THEN
        INSERT INTO points_log_advanced VALUES (NEW.id, TG_OP, NULL, NEW.points, DEFAULT);
        RETURN NEW;
    ELSIF (TG_OP = 'DELETE') THEN
        INSERT INTO points_log_advanced VALUES (OLD.id, TG_OP, OLD.points, NULL, DEFAULT);
        RETURN OLD;
    ELSIF (TG_OP = 'UPDATE') THEN
        INSERT INTO points_log_advanced VALUES (OLD.id, TG_OP, OLD.points, NEW.points, DEFAULT);
        RETURN NEW;
    END IF;
END; $$ LANGUAGE plpgsql;
\end{lstlisting}

\vfill \null

\columnbreak


\section{13. Basics of Functional Dependencies}

\subsection{Chapter Outline}
\begin{enumerate}
\item Informal Design Guidelines for Relational Databases
\item Functional Dependencies (FDs)
\item 3 Normal Forms based on Primary Keys
\item 4 General Normal Form Definitions for 2NF, 3NF (Multiple Candidate Keys)
\item BCNF (Boyce-Codd Normal Form)
\end{enumerate}

\subsection{Goals}
\begin{itemize}
\item Relational Database Design as a practical activity followed in large organizations worldwide. Relational model dominates the commerical market.
\item Have some informal guidelines that can point out problems with relational design.
\item Understand theoretical basis for analyzing designs called \textbf{functional dependencies}.
\item Understand and utilize process of \textbf{normalization} to ``improve'' / ``purify'' poor designs.
\item Understand formal basis for synthesizing good relations strictly based on knowledge of dependencies among attributes.
\end{itemize}

\subsection{Informal Design Guidelines for Relational Databases}
\begin{itemize}
\item \textbf{Relational Database Design}: Grouping of attributes to form ``good'' relation schemas.
\item Two levels of relation schemas': Logical ``user view'' level \& storage ``base relation'' level.
\end{itemize}

\subsubsection{Criteria for ``Good'' Design}
\begin{enumerate}
\item \textbf{minimality}: should express information with minimum number of distinct relations.
\item \textbf{lack of redundancy}: should minimize amount of 
redundancy among relations.
\item \textbf{Information preservation}: should preserve all 
information captured by the conceptual design (in terms of entity types, relationship types, attributes, and constraints).
\item \textbf{consistency}: among the relations
\item \textbf{efficiency}: (beyond course scope). Typically addressed in 
the physical design.
\end{enumerate}

\columnbreak

\subsection{Guidelines Summary}
\begin{enumerate}
\item \textbf{Guideline 1: Informally, each tuple in a relation should represent one entity or relationship instance. (Applies to individual relations and their attributes)}
\begin{itemize}
\item Bottom line: Design a schema that can be 
explained easily relation by relation. The 
semantics of attributes should be easy to 
interpret.
\end{itemize}
\medskip

\item \textbf{Guideline 2: Design a schema that does not suffer from update 
anomalies: (Insertion, Deletion, Modification anomalies).}
\begin{itemize}
\item If there are any anomalies present, then note them so that 
applications can be made to take them into account. (e.g. introduced for reasons as attributes needed for reporting or accounting purposes).
\item Introduction of anomalies referred to as De-Normalization.
\end{itemize}
\medskip

\item \textbf{Guideline 3: Relations should be designed such that their 
tuples will have as few NULL values as possible. }
\begin{itemize}
\item Attributes that are NULL frequently could be 
placed in separate relations (with the primary key).
\item Reasons for nulls:  Attribute not applicable or invalid, Attribute value unknown (may exist), Value known to exist, but unavailable.
\end{itemize}
\medskip

\item \textbf{Guideline 4: Avoid generation of “spurious data” when tables are joined – an absolute “MUST”.}
\begin{itemize}
\item Bad designs for a relational database may result in 
erroneous results for certain JOIN operations. Generating bad data cannot be accepted at any cost.
\item The "lossless join" (non-additive) property is used to guarantee that join operation will not create bad data. 
\item The relations should be designed to satisfy the 
lossless join condition. No spurious tuples should be generated by doing 
a natural-join of any relations.
\end{itemize}

\medskip

\item Tool for analysis: \textbf{functional dependency}. \smallskip

Methodology for ``fixing'' (bad) designs is specified by process of ``\textbf{Normalization}.''



\end{enumerate}

\null \null

\columnbreak

\subsubsection{Guideline 1: Don't mix Relations}
\begin{itemize}
\item \textbf{Guideline 1: Informally, each tuple in a relation should represent one entity or relationship instance. (Applies to individual relations and their attributes)}
\begin{itemize}
\item Do not mix attributes of different entities in same relation.
\item Only use foreign keys to refer to other entities.
\item Entity and relationship attributes be kept apart as much as possible.
\item E.g. (EMPLOYEEs, DEPARTMENTs, PROJECTs) attributes should not be mixed in the same relation (table).
\end{itemize}
\centerline{\includegraphics[width = 0.9\linewidth]{guideline1}}
\smallskip
\centerline{\includegraphics[width = 0.9\linewidth]{guideline1-2}}
\end{itemize}


\subsubsection{Guideline 2: Avoid designs with anomalies}
\begin{itemize}
\item Design a schema that does not suffer from the 
insertion, deletion and update anomalies.
\item If there are any anomalies present, then note them so 
that applications can be made to take them into 
account.
\item \textbf{Corollary of guideline 1}: Basically states that when you 
are forced to mix descriptor attributes of an entity type into the table 
for another entity type or a relationship type (for performance 
reasons or reporting requirements etc.), you should document them 
and take care of the consistency preservation via the application.
\end{itemize}

\subsubsection{Guideline 3: Minimize Null values in Tuples}
\begin{itemize}
\item Relations should be designed such that their 
tuples will have as few NULL values as possible
\item Attributes that are NULL frequently could be 
placed in separate relations (with the primary key)
\item \textbf{Reasons for nulls}:
	\begin{itemize}
	\item Attribute not applicable or invalid
	\item Attribute value unknown (may exist)
	\item Value known to exist, but unavailable.
	\end{itemize}
\end{itemize}
\smallskip
\centerline{\includegraphics[width = 0.8\linewidth]{guideline2}}

\columnbreak

\subsubsection{Guideline 4: Relations satisfy lossless (Non-Additive) join condition to avoid generating spurious tuples.}
\begin{itemize}
\item Bad designs for relational database: \textbf{erroneous results for certain JOIN operations}. The relations should be designed to satisfy the 
lossless join condition, guarantee meaningful results for join operations.
\item No spurious tuples should be generated by doing 
a natural-join of any relations. Applies to a natural join among any pairs or collections of relations.
\item How to know whether a decomposition will be lossless: Use functional dependencies and algorithm (algo 15.3, chapter 15 test losslessness property of an n-way decomposition).
\end{itemize}
\centerline{\includegraphics[width = 0.85\linewidth]{guideline4}}
\smallskip
\centerline{\includegraphics[width = 0.95\linewidth]{guideline4-1}}

\subsection{Functional Dependencies (FDs)}
\begin{itemize}
\item Used to specify \textbf{formal measures} of the 
"goodness" of relational designs.
\item And keys (derived from FDs) are used to define \textbf{normal forms} for relations.
\item FDs are \textbf{constraints} that are derived from the meaning
of and interrelationships among the data attributes.
\item  A set of attributes X \textbf{functionally determines} a set 
of attributes Y if \textbf{value of X determines a unique value for Y}.
\end{itemize}

\subsubsection{Defining Functional Dependencies}
\begin{itemize}
\item X $\rightarrow$ Y holds if whenever two tuples have the same value 
for X, they must have the same value for Y.
\item For any two tuples $t1$ and $t2$ in any relation instance:
\centerline{r(R): If t1[X] = t2[X], then t1[Y] = t2[Y]}
\item X $\rightarrow$ Y in R specifies constraint on all relat$^n$ instances r(R).
\item Written as X $\rightarrow$ Y; can be displayed graphically on a 
relation schema as in Figures. ( denoted by the arrow).
\item FDs are derived from the real-world constraints on the attribute.
\end{itemize}
\centerline{\includegraphics[width = 0.9\linewidth]{FD-1}}
\begin{itemize}
\item An FD is a (semantic, logical) property of the attributes in the schema R.
\item The constraint must hold on every relation instance r(R).
\item If K is a key of R, then K functionally determines all attributes in R.
\item We never have two distinct tuples with t1[K] = t2[K], i.e., the projection of each tuple in a relation on the K column(s) must yield distinct values.
\end{itemize}

\subsubsection{Defining FDs from Instances}
\begin{itemize}
\item To \textbf{define} FDs, need to understand meaning of attributes involved and relationship between them.
\item Given the instance (population) of a relation, all 
we can conclude is that an FD \textbf{may exist} between 
certain attributes. 
\item What we can definitely conclude is – that certain 
FDs \textbf{do not exist} because there are tuples that 
show a violation of those dependencies. 
\end{itemize}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{FD-2}}

\subsection{Further Topics in Functional Dependencies}

\subsubsection{Inference Rules for FDs}
\begin{itemize}
\item \textbf{Definition}: An FD (X $\rightarrow$ Y) is inferred from or implied by a set of dependencies F specified on R if (X $\rightarrow$ Y) \textbf{holds in 
every legal relation state r of R:}
\begin{itemize}
\item Whenever r satisfies all the dependencies in F, (X  $\rightarrow$ Y) also holds in r.
\end{itemize}
\item \textbf{Inference}: Given a set of FDs F, we can infer additional FDs that hold whenever the FDs in F hold.
\end{itemize}

\subsubsection{Armstrong's Inference Rules}
\begin{enumerate}
\item \textbf{IR1. (Reflexive)}: If Y subset-of X, then X $\rightarrow$ Y
\item \textbf{IR2. (Augmentation)}: If X $\rightarrow$ Y, then XZ $\rightarrow$ YZ.
\begin{itemize}
\item (Notation: XZ stands for X $\cup$ Z)
\end{itemize}
\item \textbf{IR3. (Transitive)}: If X $\rightarrow$ Y and Y $\rightarrow$ Z, then X $\rightarrow$ Z
\end{enumerate}
\smallskip
\begin{itemize}
\item IR1, 2, 3 form a \textbf{sound and complete} set of 
inference rules
\item \textbf{Sound}: Given a set F that holds in R, every dependency 
that can be inferred using the rules will hold in every state of 
R.
\item \textbf{Complete}: These rules and all other extended rules that 
hold can be applied to a set F of dependencies in R until no 
more dependencies can be inferred.
\end{itemize}

\columnbreak

\subsubsection{Armstrong Axioms}
\centerline{\includegraphics[width = 1\linewidth]{armstrong}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{armstrong-2}}

\null \null 
\columnbreak

\subsection{Closure}
\textbf{Two types of Closure}: \\ 

\begin{enumerate}
\item Closure of a \textbf{set F of FDs}: is the set F$^+$
(which is called “Closure of F” or “F closure”) of all FDs that can be inferred from F.
\item Closure of a \textbf{set of attributes X with respect to 
F} is the set X$^+$ of all attributes ( called Closure of X) that are \textbf{functionally determined by X}.
\end{enumerate}
\begin{itemize}
\item  X$^+$ can be calculated by repeatedly applying IR1, 
IR2, IR3 using the FDs in F.
\end{itemize}
\centerline{\includegraphics[width = 1\linewidth]{closure}}

\subsection{Equivalence of Sets of FDs}
\begin{itemize}
\item Two sets of FDs F and G are equivalent if:
\begin{itemize}
\item Every FD in F can be inferred from G, and
\item Every FD in G can be inferred from F
\item Hence, F and G are equivalent if F$^+$ =G$^+$.
\end{itemize}

\item Definition (\textbf{Covers}):
\begin{itemize}
\item F covers G if every FD in G can be inferred from F.
\item (i.e., if G$^+$ subset-of F$^+$)
\end{itemize}

\item F and G are equivalent if F covers G and G covers F.
\item \textbf{To prove equivalence of two sets of FDs}: e.g. F1 = F2, derive F1 from F2, and derive F2 from F1.
\end{itemize}

\null \null
\columnbreak

\subsection{Minimal Cover of F.D.s}
\begin{itemize} 
\item Apply inference rules to expand on a set F of FDs to arrive at F$^+$, its closure.
\item Think in opposite direction to reduce set F to its \textbf{minimal form} so that the minimal set is still equivalent to the original set F.
\item \textbf{Definition}: An attribute in a functional dependency (on 
LHS) is considered extraneous attribute if we can remove it without changing the closure of the set of dependencies. 
\item Formally, given F, (set of functional dependencies) and a functional dependency X $\rightarrow$ A in F:
\medskip
\begin{itemize}
\item  \textbf{Attribute set Y is extraneous in X if}:
\item Y is a subset of X, and
\item F logically implies (F - (X → A) $\cup$ \{ (X – Y) → A \} )
\item (aka replace (X → A) with (X – Y) → A gives back F)
\end{itemize}
\end{itemize}

\subsection{Minimal Sets of F.D.s}
 A set of FDs is \textbf{minimal} if it satisfies the 
following conditions:
\begin{enumerate}
\item Every dependency in F has a single attribute for its RHS.
\item We cannot replace any dependency X → A in F 
with a dependency Y → A, where Y is a proper subset-of X and still have a set of dependencies that is equivalent to F.
\item We cannot remove any dependency from F and 
have a set of dependencies that is equivalent to F.
\end{enumerate}
\medskip

\subsubsection{Minimal Sets of FDs as Basis for design of relations}
\begin{itemize}
\item Every set of FDs F has an equivalent minimal set.
\item Can be several equivalent minimal sets for given set F of FDs.
\item No simple algorithm for computing minimal set of FDs that is equivalent to a set F of FDs. The process of Algorithm 15.2 is used until 
no further reduction is possible.
\item Synthesis approach to design a set of relations, (Lecture 12), starts with all possible F.D.s among a set of attributes that we wish to store, computes their minimal cover and then proceeds to design a set of relations in a specific Normal Form.  (Algorithms of Ch.15.)
\end{itemize}

\null 
\columnbreak

\subsection{Computing Minimal Sets of FDs}
\centerline{\includegraphics[width = 1\linewidth]{minFD-1}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{minFD-2}} 
\medskip
\centerline{\includegraphics[width = 1\linewidth]{minFD-3}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{minFD-4}}

\null \null
\columnbreak

\subsection{Normalization of Relations (summary}
\begin{itemize}
\item \textbf{Normalization}: The process of decomposing unsatisfactory "bad" relations by breaking up their attributes into smaller relations by the process of decomposition.
\item \textbf{Normal form}: Condition using keys and FDs of a relation to 
certify whether a relation schema is in a particular normal form.
\item \textbf{2NF, 3NF, BCNF} based on keys and FDs of a relation schema
\item \textbf{4NF}: based on keys, multi-valued dependencies: MVDs;
\item \textbf{5NF}: based on keys, join dependencies : JDs;
\item Additional properties may be needed to ensure a good relational design (lossless join, dependency preservation; see Chapter 15)
\end{itemize}


\subsection{Designing a Set of Relations}
\textbf{The Approach of Relational Synthesis 
(Bottom-up Design):}
\begin{itemize}
\item Assumes that all possible functional dependencies 
are known.
\item First constructs a minimal set of FDs
\item Then applies algorithms that construct a target set 
of 3NF or BCNF relations.
\item Additional criteria may be needed to ensure the 
the set of relations in a relational database are 
satisfactory (see Algorithm 15.3).
\end{itemize}

\vfill \null
\columnbreak

\section{14. Normalization for Relational DB.}
\subsection{Properties of Decompositions}
There are two important properties of decompositions: 
\begin{enumerate}
\item Non-additive or losslessness of the corresponding join.
item Preservation of the functional dependencies. 
	\begin{itemize}
	\item Property (a) is very important, \textbf{cannot be 
	sacrificed}.
	\item Property (b) is less stringent and may be sacrificed. 
	\item If the losslessness (non-additivity) of joins is not guaranteed, 
there will be chaos in terms of lot of spurious data generated 
by database queries and transactions.
	\end{itemize}
\end{enumerate}

\subsubsection{Important Points}
\subsubsection{Relational Database Design Guidelines:}
\begin{itemize}
\item \textbf{Guideline 1:} Informally, each tuple in a relation should represent one entity or relationship instance. (Applies to individual relations and their attributes)
\item \textbf{Guideline 2:} Design a schema that does not suffer from update anomalies: (Insertion, Deletion, Modification anomalies).
\item \textbf{Guideline 3:} Relations should be designed such that their 
tuples will have as few NULL values as possible. 
\item \textbf{Guideline 4:} Avoid generation of “spurious data” when tables are joined – an absolute “MUST”. 
\end{itemize} 

\subsubsection{Functional Dependencies:} 
\begin{itemize}
\item \textbf{FDs}: used to specify formal measures of relational designs, are constraints derived from meaning and interrelationships of the data attributes, keys are used to define normal forms for 
relations.
\item \textbf{Inference Rules}: Armstrong rules for inferring new FDs.
\item \textbf{Closure}: Closure of FD as set of all FDs that can be derived from a given set.
\item \textbf{Cover}: A set of FDs X covers another set Y if all FDs in set Y can be inferred from set X.
\item \textbf{Equivalence}: Equivalence among two sets of FDs F and G based on F covering G and G covering F.
\item \textbf{Minimum Cover}: Compute the minimum cover F$_{min}$ of 
a set F as an equivalent set with no extraneous attributes on the LHS of any FD in F$_{min}$ and no redundant FD in F$_{min}$
\end{itemize}


\columnbreak

\subsection{Normalization of Relations}
\begin{itemize}
\item \textbf{Normalization:} Process of decomposing relations by breaking up their attributes into smaller relations. Done to eliminate anomalies and redundancy.
\item \textbf{Normal form:} Condition using keys and FDs of a relation to 
certify whether a relation schema is optimal.
\item \textbf{Practical use}: Normalization carried out in practice so resulting designs are of high quality, meet desirable properties. 
\item Practical utility of 4NF, 5NF normal forms when constraints are hard to understand or to detect are questionable. Normalise just up to BCNF.
\item \textbf{Denormalization}: Process of storing join of higher normal form relations as a base relation—which is in a lower normal form.
\end{itemize}
\centerline{\includegraphics[width = 0.6\linewidth]{normalization}}


\subsection{Definitions of Keys \& Attributes Participating in Keys}
\begin{itemize}
\item \textbf{Superkey} of a relation schema R = \{A1, A2, ...., An\} is set of attributes S subset-of R with property:
\begin{itemize}
\item no two tuples t1 and t2 in any legal 
relation state r of R will have t1[S] = t2[S].
\end{itemize}
\item \textbf{A key} K is a \textbf{superkey} with additional 
property that removal of any attribute from K will cause K not to be a superkey any more.
\item \textbf{Candidate Key}: If relation schema $>$ one key, each 
is called a candidate key.
\begin{itemize}
\item One of candidate keys arbitrarily designated as primary key, others called candidate keys (alternate keys).
\end{itemize}
\item \textbf{Prime attribute}: member of some candidate key.
\item \textbf{Nonprime attribute}: not member of any candidate key.
\end{itemize}

\subsubsection{Example of Keys}
\centerline{\includegraphics[width = 1\linewidth]{keys}}

\subsection{First Normal Form (1NF)}
\begin{itemize}
\item \textbf{1NF}: Table said to be in 1NF if \textbf{every attribute possesses only atomic values}.
\item \textbf{Disallows}: composite attributes, multivalued attributes, nested relations (attributes whose values for an individual tuple are non-atomic).
\item \textbf{Functional Dependency Analysis}: For a relation to be 1NF, every attribute must functionally be dependent on primary key.
\end{itemize}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{1NF}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{1NF-2}}


\subsection{Second Normal Form (2NF)}
\begin{itemize}
\item \textbf{2NF}: A relation schema R in 2NF if every \textbf{non-prime attribute} A in R is \textbf{fully functionally dependent} on (every) \textbf{ENTIRE} primary key.
\item \textbf{Understanding}: (don't mix relations).
\item R decomposed into 2NF relations via \textbf{2NF normalization}: decompose so as to achieve full functional dependence on entire primary key in each (new) relation.
\item \textbf{Functional Dependency Analysis}: For 2NF, non-prime attribute must be \textbf{fully functionally dependent} on primary key.
\item By converting to 2NF, \textbf{update anomalies are eliminated}.
\end{itemize}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{2NF}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{2NF-2}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{2NF-3}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{2NF-4}}

\columnbreak	

\subsection{Third Normal Form (3NF)}
\begin{itemize}
\item \textbf{3NF}: A relation schema R in 3NF if in 2NF and
no non-prime attribute A in R is transitively dependent on the primary 
key.
\begin{itemize}
\item If whenever a FD (X $\rightarrow$ A) holds in R, then either:
\item (a) X is a superkey of R, or
\item (b) A is a prime attribute of R. (member of candidate key)
\item (\textbf{Every non key field} is non-transitively dependent on the primary key.)
\end{itemize}
\item a) catches 2NF violations due to non-full functional dep, and 3NF violations due to transitive dependencies.
\item b) allows certain dependencies up to 3NF (which are disallowed in BCNF)
\end{itemize}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{3NF}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{3NF-2}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{3NF-0}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{3NF-3}}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{2NF-3NF}}

\subsection{Boyce-Codd Normal Form (BCNF, 3NF+) }
\begin{itemize}
\item \textbf{BCNF}: Relation schema R in BCNF if:
\begin{itemize}
\item If whenever a FD (X $\rightarrow$ A) holds in R, then:
\item (a) X is a superkey of R.
\end{itemize}
\item Considered strong form of 3NF. Relation NOT in BCNF should be decomposed to achieve BCNF, meet property that every FD has \textbf{LHS which must be superkey}.
\item However, decomposition possibly forgoes preservation of all functional dependencies in the decomposed relations.
\item \textbf{``More but not All'' violation} method for BCNF:
	\begin{enumerate}
	\item Derive closure for each attribute subset.
	\item If any closures has "more" attributes on the RHS compared to LHS, but "not all" attributes compared to the table, then it violates BCNF.
	\item Can stop the algorithm and determine that it is not in BCNF
	\end{enumerate}
\end{itemize}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{BCNF}}

\subsubsection{BCNF Normalization}
\centerline{\includegraphics[width = 1\linewidth]{BCNF-2}}

\subsection{Testing Binary Decomposition for Lossless Join}
\begin{itemize}
\item \textbf{Binary Decomposition}:  Decomposition of a 
relation R into two relations.
\item \textbf{NJB Property}: (Non-additive Join test for 
Binary decompositions).
\item A \textbf{Decomposition D = \{R1, R2\} of R} has the  \textbf{lossless join property} with respect to a set of functional dependencies F on R 
if and only if either:
\begin{itemize}
\item The f.d. ((R1 $\cap$ R2) $\rightarrow$ (R1- R2)) is in F$^+$, or
\item The f.d. ((R1  $\cap$ R2) $\rightarrow$ (R2 - R1)) is in F$^+$
\end{itemize}
\medskip
\item aka \textbf{(R1 INTERSECT R2) → (R1 - R2) or (R2 - R1)}.
\end{itemize}
\medskip
\centerline{\includegraphics[width = 1\linewidth]{NJB}}

\subsubsection{General Procedure for achieving BCNF
when a relation fails BCNF}
\begin{itemize}
\item Let R be the relation not in BCNF.
\item Let X be a subset-of R, and let X → Y be the FD that causes BCNF violation.
\item Then R may be decomposed into two relations:
	\begin{itemize}
	\item (i) (R – Y) and (ii) (X U Y).
	\item If either (R –Y) or (X U Y) not in BCNF, \\
		repeat the process.
	\end{itemize}
\end{itemize}








\end{multicols*}
\end{document}